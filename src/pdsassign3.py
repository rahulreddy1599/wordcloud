# -*- coding: utf-8 -*-
"""pdsassign3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PJvaBBsNGEiM9lzLW2jNjsFF9Ml6h7Sr
"""

# Importing required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from collections import Counter

# Loading data
Data = pd.read_csv("Corona_NLP_test.csv")

# Tokenization(converting text to tokens) and performing stop word removal
stop_words = set(stopwords.words('english'))
tokens = Data['OriginalTweet'].apply(word_tokenize).explode().str.lower()
tokens = tokens[~tokens.isin(stop_words)]

# Counting word frequencies
freq = Counter(tokens)

# Creating word cloud
wordcloud = WordCloud(width = 800, height = 800,
                      background_color ='white',
                      stopwords = stop_words,
                      min_font_size = 10).generate_from_frequencies(freq)

# Plotting the word cloud
plt.figure(figsize = (8, 8), facecolor = None)
plt.imshow(wordcloud)
plt.axis("off")
plt.tight_layout(pad = 0)

# Saving the word cloud
plt.savefig("wordcloud.png")